{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Reefer Predictive Maintenance Solution This project is to demonstrate how to perform real time scoring on Reefer container metrics. The runtime environment in production will look like: The Reefer container is a IoT device, which emits container metrics every 15 minutes via the MQTT protocol. The first component receiving those messages is Apache Nifi to transform the metrics message to a kafka event. Kafka is used as the event backbone and event sourcing so microservices, deployed on openshift, can consume and publish messages. For persistence reason, we may leverage big data type of storage like Cassandra to persist the container metrics over a longer time period. This datasource is used by the Data Scientists to do its data preparation and build training and test sets and build model. Data scientists can run Jupyter lab on OpenShift and build a model to be deployed as python microservice, consumer of kafka Reefer metrics events. The action will be to change the state of the Reefer entity via an events to the containers topic. Component view While for the minimum viable demonstration the components looks like in the figure below: A web app, deployed on Openshift, is running a simulator to simulate the generation of Reefer container metrics while the container is at sea or during end to end transportation. The app exposes a simple POST operation with a control object to control the simulation. Here is an example of such control.json { 'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 1000, 'good_temperature': 4.4 } See this section to build and deploy the simulator web app. A curl script will do the post of this json object. See this paragraph. The metrics events are sent to the containerMetrics topic in Kafka. The predictive scoring is a consumer of such events, read one event at a time and call the model internally, then sends a new event when maintenance is required. See the note for details. The maintenance requirement is an event in the containers topic. The last element is to trace the container maintenance event, in real application, this component should trigger a business process to get human performing the maintenance. Pre-requisites Start by cloning this project using the command: git clone https://github.com/jbcodeforce/refarch-reefer-ml Building the python environment as docker image To avoid impacting our environment, we use a dockerfile to get the basic of python 3.7.x and other needed modules like kafka, http requests, pytest... So to build your python image with all the needed libraries, use the following commands: cd docker docker build -f docker-python-tools -t ibmcase/python . Be sure to have Event Stream or kafka running Create the Event Stream service using the IBM Cloud catalog The following diagram illustrates the topics configured in IBM Cloud Event Stream service: In the service credentials creates new credentials to get the Kafka broker list, the admin URL and the api_key needed to authenticate the consumers or producers. Machine Learning Work To review the problem of predictive maintenance read this article. Generate data with the Reefer simulator Well we do not have real Reefer data. But we may be able to simulate them. As this is not production work, we should be able to get the end to end story still working from a solution point of view. The historical data need to represent failure, and represent the characteristics of a Reefer container. We can imagine it includes a lot of sensors to get interesting correlated or independant features. We have implemented a simulator to create those metrics to be used to build the model inside Jupiter notebook and with sklearn or tensorflow library. Start python env . / startPythonEnv root @03721594782f : cd / home / simulator From this shell, first specify where python should find the new modules, by setting the environment variable PYTHONPATH: root @03721594782f :/ # export PYTHONPATH =/ home Generate power off metrics When the reefer containers lose power at some time, the temperature within the container starts raising. The simulator accepts different arguments: usage reefer_simulator --stype [poweroff | co2sensor | atsea] --cid <container ID> --records <the number of records to generate> --temp <expected temperature for the goods> --file <the filename to create (without .csv)> --append [yes | no] (reuse the data file) root @03721594782f : python reefer_simulator_tool . py -- stype poweroff -- cid 101 -- records 1000 -- temp 4 -- file .. / ml / data / metrics . csv -- append yes Generating 1000 poweroff metrics Timestamp ID Temperature ( celsius ) Target_Temperature ( celsius ) Power PowerConsumption ContentType O2 CO2 Time_Door_Open Maintenance_Required Defrost_Cycle 1.000000 2019 - 06 - 30 T15 : 43 Z 101 3.416766 4 17.698034 6.662044 1 11 1 8.735273 0 6 1.001001 2019 - 06 - 30 T15 : 43 Z 101 4.973630 4 3.701072 8.457314 1 13 3 5.699655 0 6 1.002002 2019 - 06 - 30 T15 : 43 Z 101 1.299275 4 7.629094 Generate Co2 sensor malfunction in same file In the same way as above the simulator can generate data for Co2 sensor malfunction using the command: python reefer_simulator_tool.py --stype co2sensor --cid 101 --records 1000 --temp 4 --file ../ml/data/metrics.csv --append yes Note The simulator is integrated in the event producer to send real time events to kafka, as if the Reefer container was loaded with fresh goods and is travelling oversea. A consumer code can call the predictive model to assess if maintenance is required and post new event on a containers topic. Create the model Now we will use a local version of Jupyter notebook to load the logistic regression nodebook in the ml folder. Start a jupyter server using a docker image: cd ml docker run --rm -p 10000:8888 -v \"$PWD\":/home/jovyan/work jupyter/datascience-notebook Then open a web browser to http://localhost:10000 and then open the model_logistic_regression.ipynb and run it step by step. The notebook includes comments to explain how the model is done. We use logistic regression to build a binary classification (maintenance required or not), as the data are simulated, and the focus is not in the model building, but more on the end to end process. The notebook persists the trained model as a pickle file so it can be loaded by a python module or another model. For more information on using the Jupyter notebook, here is a product documentation . Use the model in another notebook: We can use a second notebook to assess some one record test using the pickle serialized model. The notebook is named predictMaintenance.ipynb The Simulator as webapp This is a simple python Flask web app exposing a REST POST end point and producing Reefer metrics event to kafka. The POST operation in on the /control url. The control object, to generate 1000 events with the co2sensor simulation looks like: { 'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 1000, 'good_temperature': 4.4 } Run it locally To build the simulator using the s2i CLI : s2i build --copy . centos/python-36-centos7 ibmcase/reefersimulator Then to run it locally, use the local script ./runReeferSimulator.sh or after setting the environment variables for kafka launch the docker container like: docker run -p 8080:8080 -e KAFKA_ENV=$KAFKA_ENV -e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_APIKEY=$KAFKA_APIKEY ibmcase/reefersimulator Build and run on OpentShift To deploy the code to an openshift cluster do the following: Login to the openshift cluster. oc login -u apikey -p <apikey> --server=https://... Create a project if not done already: oc new-project reefershipmentsolution --description=\"A Reefer container shipment solution\" Remember the project is mapped to a kubernestes namespace, but includes other componetns too Create an app from the source code, and use source to image build process to deploy the app. You can use a subdirectory of your source code repository by specifying a --context-dir flag. oc new-app python:latest~https://github.com/jbcodeforce/refarch-reefer-ml.git --context-dir=simulator --name reefersimulator Then to track the build progress: oc logs -f bc/reefersimulator The dependencies are loaded, the build is scheduled and executed, the image is uploaded to the registry, and started. To display information about the build configuration for the application: oc describe bc/reefersimulator To trigger a remote build (run on Openshift) from local source code do the following command: oc start-build reefersimulator --from-file=. Set environment variables For Broker URLs oc set env dc/reefersimulator KAFKA_BROKERS=kafka03-prod02.messagehub.services.us-south.blu.... For apikey: oc set env dc/reefersimulator KAFKA_APIKEY=\"\" For the kafka runtime env: oc set env dc/reefersimulator KAFKA_ENV=\"IBM_CLOUD\" Get all environment variables set for a given pod: (det the pod id with oc get pod ) oc set env pod/reefersimulator-4-tq27j --list Once the build is done you should see the container up and running oc get pod reefersimulator-3-build 0/1 Completed 0 15m reefersimulator-3-jdh2v 1/1 Running 0 1m Note The first time the container start, it may crash as he environment variables like KAFKA_APIKEY is not defined. You can use the ./scripts/setenv.sh SET command to create the needed environment variable. To make it visible externally, you need to add a route for this deployment: Use Create Route button on top right, The enter a name and select the existing service Once created, the URL of the app is visible in the route list panel: Add the host name in your local /etc/hosts or be sure the hostname is defined in DNS server. Map to the IP address of the kubernetes proxy server end point. Test sending a simulation control to the POST api The script sendSimulControl.sh is used for that. ``` pwd refarch-reefer-ml cd scripts ./sendSimulControl.sh reefersimulatorroute-reefershipmentsolution.apps.green-with-envy.ocp.csplab.local co2sensor ``` Looking at the logs from the pod using `oc logs reefersimulator-3-jdh2v` you can see something like: ``` \"POST /order HTTP/1.1\" 404 232 \"-\" \"curl/7.54.0\" {'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 10, 'good_temperature': 4.4} Generating 10 Co2 metrics ``` We will see how those events are processed in the next section. The predictive scoring microservice Applying the same pattern as the simulation webapp, we implement a kafka consumer and producer in python that call the serialized analytic model. The code in the scoring folder. Applying a TDD approach we start by a TestScoring.py class. import unittest from scoring.predictservice import PredictService class TestScoreMetric ( unittest . TestCase ): def testCreation ( self ): serv = PredictService if __name__ == '__main__' : unittest . main () Use the same python environment with docker: . / startPythonEnv root @1 de81b16f940 : / # cd / home / scoring / root @1 de81b16f940 : / home / scoring # python TestScoring . py Test fails, so let add the scoring service with a constructor, and load the serialized pickle model (which was copied from the ml folder). import pickle class PredictService : model = pickle . load ( open ( \"model_logistic_regression.pkl\" , \"rb\" ), encoding = 'latin1' ) Next we need to test a predict on an event formated as a csv string. The test looks like: serv = PredictService() header=\"\"\"Timestamp, ID, Temperature(celsius), Target_Temperature(celsius), Power, PowerConsumption, ContentType, O2, CO2, Time_Door_Open, Maintenance_Required, Defrost_Cycle\"\"\" event=\"2019-04-01 T16:29 Z,1813, 101, 4.291843460900875,4.4,0,10.273342381017777,3,4334.920958996634,4.9631508046318755,1,0,6\"\"\" record=header+\"\\n\"+event print(serv.predict(record)) So the scoring works, now we need to code the scoring application that will be deployed to Openshift cluster, and which acts as a consumer of container metrics events and a producer container events. The code of this app is here Run locally Under scoring folde, set the environment variables for KAFKAuse the commands The script does this for you: Deploy to Openshift The first time we need to add the application to the existing project, run the following command: oc new-app python:latest~https://github.com/jbcodeforce/refarch-reefer-ml.git --context-dir=scoring --name reeferpredictivescoring This command will run a source to image, build all the needed yaml files for the kubernetes deployment and start the application in a pod. An list of running pods, should show the build prod for this application: oc get pods reeferpredictivescoring-1-build 1/1 Running 0 24s To run the build again after commit code to github: oc start-build reeferpredictivescoring To be able to run on opanshift, the APP_FILE environment variable has to be set to ScoringApp.py. This can be done in the environment file under the .s2i folder.","title":"Introduction"},{"location":"#reefer-predictive-maintenance-solution","text":"This project is to demonstrate how to perform real time scoring on Reefer container metrics. The runtime environment in production will look like: The Reefer container is a IoT device, which emits container metrics every 15 minutes via the MQTT protocol. The first component receiving those messages is Apache Nifi to transform the metrics message to a kafka event. Kafka is used as the event backbone and event sourcing so microservices, deployed on openshift, can consume and publish messages. For persistence reason, we may leverage big data type of storage like Cassandra to persist the container metrics over a longer time period. This datasource is used by the Data Scientists to do its data preparation and build training and test sets and build model. Data scientists can run Jupyter lab on OpenShift and build a model to be deployed as python microservice, consumer of kafka Reefer metrics events. The action will be to change the state of the Reefer entity via an events to the containers topic.","title":"Reefer Predictive Maintenance Solution"},{"location":"#component-view","text":"While for the minimum viable demonstration the components looks like in the figure below: A web app, deployed on Openshift, is running a simulator to simulate the generation of Reefer container metrics while the container is at sea or during end to end transportation. The app exposes a simple POST operation with a control object to control the simulation. Here is an example of such control.json { 'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 1000, 'good_temperature': 4.4 } See this section to build and deploy the simulator web app. A curl script will do the post of this json object. See this paragraph. The metrics events are sent to the containerMetrics topic in Kafka. The predictive scoring is a consumer of such events, read one event at a time and call the model internally, then sends a new event when maintenance is required. See the note for details. The maintenance requirement is an event in the containers topic. The last element is to trace the container maintenance event, in real application, this component should trigger a business process to get human performing the maintenance.","title":"Component view"},{"location":"#pre-requisites","text":"Start by cloning this project using the command: git clone https://github.com/jbcodeforce/refarch-reefer-ml","title":"Pre-requisites"},{"location":"#building-the-python-environment-as-docker-image","text":"To avoid impacting our environment, we use a dockerfile to get the basic of python 3.7.x and other needed modules like kafka, http requests, pytest... So to build your python image with all the needed libraries, use the following commands: cd docker docker build -f docker-python-tools -t ibmcase/python .","title":"Building the python environment as docker image"},{"location":"#be-sure-to-have-event-stream-or-kafka-running","text":"Create the Event Stream service using the IBM Cloud catalog The following diagram illustrates the topics configured in IBM Cloud Event Stream service: In the service credentials creates new credentials to get the Kafka broker list, the admin URL and the api_key needed to authenticate the consumers or producers.","title":"Be sure to have Event Stream or kafka running"},{"location":"#machine-learning-work","text":"To review the problem of predictive maintenance read this article.","title":"Machine Learning Work"},{"location":"#generate-data-with-the-reefer-simulator","text":"Well we do not have real Reefer data. But we may be able to simulate them. As this is not production work, we should be able to get the end to end story still working from a solution point of view. The historical data need to represent failure, and represent the characteristics of a Reefer container. We can imagine it includes a lot of sensors to get interesting correlated or independant features. We have implemented a simulator to create those metrics to be used to build the model inside Jupiter notebook and with sklearn or tensorflow library.","title":"Generate data with the Reefer simulator"},{"location":"#start-python-env","text":". / startPythonEnv root @03721594782f : cd / home / simulator From this shell, first specify where python should find the new modules, by setting the environment variable PYTHONPATH: root @03721594782f :/ # export PYTHONPATH =/ home","title":"Start python env"},{"location":"#generate-power-off-metrics","text":"When the reefer containers lose power at some time, the temperature within the container starts raising. The simulator accepts different arguments: usage reefer_simulator --stype [poweroff | co2sensor | atsea] --cid <container ID> --records <the number of records to generate> --temp <expected temperature for the goods> --file <the filename to create (without .csv)> --append [yes | no] (reuse the data file) root @03721594782f : python reefer_simulator_tool . py -- stype poweroff -- cid 101 -- records 1000 -- temp 4 -- file .. / ml / data / metrics . csv -- append yes Generating 1000 poweroff metrics Timestamp ID Temperature ( celsius ) Target_Temperature ( celsius ) Power PowerConsumption ContentType O2 CO2 Time_Door_Open Maintenance_Required Defrost_Cycle 1.000000 2019 - 06 - 30 T15 : 43 Z 101 3.416766 4 17.698034 6.662044 1 11 1 8.735273 0 6 1.001001 2019 - 06 - 30 T15 : 43 Z 101 4.973630 4 3.701072 8.457314 1 13 3 5.699655 0 6 1.002002 2019 - 06 - 30 T15 : 43 Z 101 1.299275 4 7.629094","title":"Generate power off metrics"},{"location":"#generate-co2-sensor-malfunction-in-same-file","text":"In the same way as above the simulator can generate data for Co2 sensor malfunction using the command: python reefer_simulator_tool.py --stype co2sensor --cid 101 --records 1000 --temp 4 --file ../ml/data/metrics.csv --append yes Note The simulator is integrated in the event producer to send real time events to kafka, as if the Reefer container was loaded with fresh goods and is travelling oversea. A consumer code can call the predictive model to assess if maintenance is required and post new event on a containers topic.","title":"Generate Co2 sensor malfunction in same file"},{"location":"#create-the-model","text":"Now we will use a local version of Jupyter notebook to load the logistic regression nodebook in the ml folder. Start a jupyter server using a docker image: cd ml docker run --rm -p 10000:8888 -v \"$PWD\":/home/jovyan/work jupyter/datascience-notebook Then open a web browser to http://localhost:10000 and then open the model_logistic_regression.ipynb and run it step by step. The notebook includes comments to explain how the model is done. We use logistic regression to build a binary classification (maintenance required or not), as the data are simulated, and the focus is not in the model building, but more on the end to end process. The notebook persists the trained model as a pickle file so it can be loaded by a python module or another model. For more information on using the Jupyter notebook, here is a product documentation . Use the model in another notebook: We can use a second notebook to assess some one record test using the pickle serialized model. The notebook is named predictMaintenance.ipynb","title":"Create the model"},{"location":"#the-simulator-as-webapp","text":"This is a simple python Flask web app exposing a REST POST end point and producing Reefer metrics event to kafka. The POST operation in on the /control url. The control object, to generate 1000 events with the co2sensor simulation looks like: { 'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 1000, 'good_temperature': 4.4 }","title":"The Simulator as webapp"},{"location":"#run-it-locally","text":"To build the simulator using the s2i CLI : s2i build --copy . centos/python-36-centos7 ibmcase/reefersimulator Then to run it locally, use the local script ./runReeferSimulator.sh or after setting the environment variables for kafka launch the docker container like: docker run -p 8080:8080 -e KAFKA_ENV=$KAFKA_ENV -e KAFKA_BROKERS=$KAFKA_BROKERS -e KAFKA_APIKEY=$KAFKA_APIKEY ibmcase/reefersimulator","title":"Run it locally"},{"location":"#build-and-run-on-opentshift","text":"To deploy the code to an openshift cluster do the following: Login to the openshift cluster. oc login -u apikey -p <apikey> --server=https://... Create a project if not done already: oc new-project reefershipmentsolution --description=\"A Reefer container shipment solution\" Remember the project is mapped to a kubernestes namespace, but includes other componetns too Create an app from the source code, and use source to image build process to deploy the app. You can use a subdirectory of your source code repository by specifying a --context-dir flag. oc new-app python:latest~https://github.com/jbcodeforce/refarch-reefer-ml.git --context-dir=simulator --name reefersimulator Then to track the build progress: oc logs -f bc/reefersimulator The dependencies are loaded, the build is scheduled and executed, the image is uploaded to the registry, and started. To display information about the build configuration for the application: oc describe bc/reefersimulator To trigger a remote build (run on Openshift) from local source code do the following command: oc start-build reefersimulator --from-file=. Set environment variables For Broker URLs oc set env dc/reefersimulator KAFKA_BROKERS=kafka03-prod02.messagehub.services.us-south.blu.... For apikey: oc set env dc/reefersimulator KAFKA_APIKEY=\"\" For the kafka runtime env: oc set env dc/reefersimulator KAFKA_ENV=\"IBM_CLOUD\" Get all environment variables set for a given pod: (det the pod id with oc get pod ) oc set env pod/reefersimulator-4-tq27j --list Once the build is done you should see the container up and running oc get pod reefersimulator-3-build 0/1 Completed 0 15m reefersimulator-3-jdh2v 1/1 Running 0 1m Note The first time the container start, it may crash as he environment variables like KAFKA_APIKEY is not defined. You can use the ./scripts/setenv.sh SET command to create the needed environment variable. To make it visible externally, you need to add a route for this deployment: Use Create Route button on top right, The enter a name and select the existing service Once created, the URL of the app is visible in the route list panel: Add the host name in your local /etc/hosts or be sure the hostname is defined in DNS server. Map to the IP address of the kubernetes proxy server end point.","title":"Build and run on OpentShift"},{"location":"#test-sending-a-simulation-control-to-the-post-api","text":"The script sendSimulControl.sh is used for that. ``` pwd refarch-reefer-ml cd scripts ./sendSimulControl.sh reefersimulatorroute-reefershipmentsolution.apps.green-with-envy.ocp.csplab.local co2sensor ``` Looking at the logs from the pod using `oc logs reefersimulator-3-jdh2v` you can see something like: ``` \"POST /order HTTP/1.1\" 404 232 \"-\" \"curl/7.54.0\" {'containerID': 'c100', 'simulation': 'co2sensor', 'nb_of_records': 10, 'good_temperature': 4.4} Generating 10 Co2 metrics ``` We will see how those events are processed in the next section.","title":"Test sending a simulation control to the POST api"},{"location":"#the-predictive-scoring-microservice","text":"Applying the same pattern as the simulation webapp, we implement a kafka consumer and producer in python that call the serialized analytic model. The code in the scoring folder. Applying a TDD approach we start by a TestScoring.py class. import unittest from scoring.predictservice import PredictService class TestScoreMetric ( unittest . TestCase ): def testCreation ( self ): serv = PredictService if __name__ == '__main__' : unittest . main () Use the same python environment with docker: . / startPythonEnv root @1 de81b16f940 : / # cd / home / scoring / root @1 de81b16f940 : / home / scoring # python TestScoring . py Test fails, so let add the scoring service with a constructor, and load the serialized pickle model (which was copied from the ml folder). import pickle class PredictService : model = pickle . load ( open ( \"model_logistic_regression.pkl\" , \"rb\" ), encoding = 'latin1' ) Next we need to test a predict on an event formated as a csv string. The test looks like: serv = PredictService() header=\"\"\"Timestamp, ID, Temperature(celsius), Target_Temperature(celsius), Power, PowerConsumption, ContentType, O2, CO2, Time_Door_Open, Maintenance_Required, Defrost_Cycle\"\"\" event=\"2019-04-01 T16:29 Z,1813, 101, 4.291843460900875,4.4,0,10.273342381017777,3,4334.920958996634,4.9631508046318755,1,0,6\"\"\" record=header+\"\\n\"+event print(serv.predict(record)) So the scoring works, now we need to code the scoring application that will be deployed to Openshift cluster, and which acts as a consumer of container metrics events and a producer container events. The code of this app is here","title":"The predictive scoring microservice"},{"location":"#run-locally","text":"Under scoring folde, set the environment variables for KAFKAuse the commands The script does this for you:","title":"Run locally"},{"location":"#deploy-to-openshift","text":"The first time we need to add the application to the existing project, run the following command: oc new-app python:latest~https://github.com/jbcodeforce/refarch-reefer-ml.git --context-dir=scoring --name reeferpredictivescoring This command will run a source to image, build all the needed yaml files for the kubernetes deployment and start the application in a pod. An list of running pods, should show the build prod for this application: oc get pods reeferpredictivescoring-1-build 1/1 Running 0 24s To run the build again after commit code to github: oc start-build reeferpredictivescoring To be able to run on opanshift, the APP_FILE environment variable has to be set to ScoringApp.py. This can be done in the environment file under the .s2i folder.","title":"Deploy to Openshift"},{"location":"integration-tests/","text":"Integration tests to proof the solution Recall that the architecture of the deployed components look like in the figure below. So the first component to start is the container consumer which consumer events on the kafka containers topic. This is where the microservices will post message about a Reefer container. Start Reefer container events consumer In the consumer folder use the command: ./runContainerConsumer.sh This script the docker python image, we built earlier. Start the predictive scoring service We can run it locally or on kubernetes cluster like openshift. Under scoring folder, use the command:","title":"Run integration tests"},{"location":"integration-tests/#integration-tests-to-proof-the-solution","text":"Recall that the architecture of the deployed components look like in the figure below. So the first component to start is the container consumer which consumer events on the kafka containers topic. This is where the microservices will post message about a Reefer container.","title":"Integration tests to proof the solution"},{"location":"integration-tests/#start-reefer-container-events-consumer","text":"In the consumer folder use the command: ./runContainerConsumer.sh This script the docker python image, we built earlier.","title":"Start Reefer container events consumer"},{"location":"integration-tests/#start-the-predictive-scoring-service","text":"We can run it locally or on kubernetes cluster like openshift. Under scoring folder, use the command:","title":"Start the predictive scoring service"},{"location":"predictive-maintenance/","text":"Reefer Container Predictive Maintenance In this section, we discuss how to build an analytic model using machine learning techniques from data coming from event store like kafka. We train the model with the help of historical data to predict whether maintenance is required for the reefer container at a certain point in time. You will learn how to simulate date for reefer, develop the predictive maintenance model, and integrate the model into an application. Introduction A reefer container is a refrigerated shipping container used to store or transport frozen or cold goods perishable items or goods that require temperature control. Reefers make an excellent, portable solution for short or long term storage and can be used to ship or truck goods over long distances as they can be plugged into the power station on ships or have it clipped on generators attached. Perishable products must be kept at a controlled temperature, from point of origin to delivery to retailer or pharmacy. The logistics industry refers to this as the \u201ccold chain\u201d and it encompasses both \u201creefers\u201d (refrigerated containers) as well as warehouses, distribution centers and the final storage or holding areas. Throughout this chain the risk of failure is ever-present, meaning there is always a possibility of cargo exceeding permissible or safe temperature levels, even if only briefly. For example, a truck might be stopped without power in desert heat, allowing temperatures in the reefer to rise. Then power is restored and the temperature in the container comes back down, but the product is damaged. When cargo with such as any of those items listed above are exposed to temperatures outside of prescribed limits it can be damaged. In some cases this is evident, such as with bananas, but in other situations, like the transport of vaccines, it may not be apparent that damage has occurred and the vaccine becomes ineffective. For some products, going over temperature, even only briefly, can reduce shelf life dramatically, incurring substantial costs when it cannot be sold. Organizations contracting to ship perishable products often specify the permissible temperature range. However, even if it is possible to show that product was exposed to conditions outside of those contracted, proving where it happened, and thus responsibility, can be much harder. Predictive maintenance problem statement The success of predictive maintenance models depend on three main components: having the right data framing the problem appropriately evaluating the predictions properly From a methodology point of view the Data Scientist needs to address the following questions: What type of failure to consider and which one to predict? What kind of failure is happening? slow degradation or instantaneous failure? What could be the relation between a product characteristics and the failure? What kind of measure exist to assess the given characteristic? Which measurements correspond to good functioning and which ones correspond to failure? How often metrics are reported? What question the model should answer? What kind of output should the model give? How long in advance should the model be able to indicate that a failure will occur? What are the business impact to do not predict the failure? and predicting false negative failure? What is the expected accuracy? Reefer problem types There are multiple different potential issues that could happen to a refrigerator container. We are choosing to model the \"Sensor Malfunctions\" issue: Sensors in the refrigeration unit need to be calibrated and be continuously operational. An example of failure may come from the air sensor making inaccurate readings of temperatures, which leads to sploiled content. A potential reason may come from a faulty calibration, which can go unnoticed for a good time period. It may be difficult to know if there is an issue or not. The other common potential issues are: Fluid leaks, like engine oil, coolant liquid. The preassure sensors added to the circuit may help identify preassure lost over time. Faulty belts and hoses. Faulty calibration: A non-calibrated reefer can cool at a slower or faster rate than desired. Damaged Air Chute. Condenser Issues like broken or damaged coils, clamps or bolts missing, and leaks. Door Seals damaged. Blocked air passage: to keep the temperature homogenous inside the reefer. So the question we want to answer is: does the Reefer keep accurate temperature overtime between what is set versus what is measured? Modeling techniques The model uses the generated data from above scenarios: When the container's door is open for a longer time - this gives a false positive that maintainence is required. When sensors are malfunctioning, it records arbitrary readings. When the readings are normal. We have currently trained our model on 3000 datapoints from the three scenarios above. There are different modeling approach to tackle predictive maintenance: regression model classification to predict failure for a given time period classify anomalous behavior: classes are not known in advance. Normal operation is known. compute probability of failure over time Code execution The simulator continuosly generates container metrics, publishes it to Kafka and run the predictMaintainence.ipynb to predict if maintainence is sought at this point in time. Model description We are using Machine Learning supervised learning here. There are two types of supervised learning - 1) Classification: Predict a categorical response, 2) Regression: Predict a continuous response Linear regression Pros: 1) Fast 2) No tuning required 3) Highly interpretable 4) Well-understood Cons: 1) Unlikely to produce the best predictive accuracy 2) Presumes a linear relationship between the features and response 3) If the relationship is highly non-linear as with many scenarios, linear relationship will not effectively model the relationship and its prediction would not be accurate Naive Bayes classification Naive Bayes is a probabilistic classifier inspired by the Bayes theorem under a simple assumption which is the attributes are conditionally independent. The classification is conducted by deriving the maximum posterior which is the maximal P(Ci|X) with the above assumption applying to Bayes theorem. This assumption greatly reduces the computational cost by only counting the class distribution. Even though the assumption is not valid in most cases since the attributes are dependent, surprisingly Naive Bayes has able to perform impressively. Naive Bayes is a very simple algorithm to implement and good results have obtained in most cases. It can be easily scalable to larger datasets since it takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers. Naive Bayes can suffer from a problem called the zero probability problem. When the conditional probability is zero for a particular attribute, it fails to give a valid prediction. This needs to be fixed explicitly using a Laplacian estimator. Model evaluation We are using Root Mean Squared Error (RMSE) for evaluating the model performance. Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors. Classification does better here as the scenarion is more of a classification problem. References Understand Reefer container For modeling predictive maintenance we found this article from BigData Republique, on Medium, very interesting. PREDICTION OF TEMPERATURE INSIDE A REFRIGERATED CONTAINER IN THE PRESENCE OF PERISHABLE GOODS Temperature Monitoring During Transportation, Storage and Processing of Perishable Products Understanding machine learning classifiers","title":"Reefer Container Predictive Maintenance"},{"location":"predictive-maintenance/#reefer-container-predictive-maintenance","text":"In this section, we discuss how to build an analytic model using machine learning techniques from data coming from event store like kafka. We train the model with the help of historical data to predict whether maintenance is required for the reefer container at a certain point in time. You will learn how to simulate date for reefer, develop the predictive maintenance model, and integrate the model into an application.","title":"Reefer Container Predictive Maintenance"},{"location":"predictive-maintenance/#introduction","text":"A reefer container is a refrigerated shipping container used to store or transport frozen or cold goods perishable items or goods that require temperature control. Reefers make an excellent, portable solution for short or long term storage and can be used to ship or truck goods over long distances as they can be plugged into the power station on ships or have it clipped on generators attached. Perishable products must be kept at a controlled temperature, from point of origin to delivery to retailer or pharmacy. The logistics industry refers to this as the \u201ccold chain\u201d and it encompasses both \u201creefers\u201d (refrigerated containers) as well as warehouses, distribution centers and the final storage or holding areas. Throughout this chain the risk of failure is ever-present, meaning there is always a possibility of cargo exceeding permissible or safe temperature levels, even if only briefly. For example, a truck might be stopped without power in desert heat, allowing temperatures in the reefer to rise. Then power is restored and the temperature in the container comes back down, but the product is damaged. When cargo with such as any of those items listed above are exposed to temperatures outside of prescribed limits it can be damaged. In some cases this is evident, such as with bananas, but in other situations, like the transport of vaccines, it may not be apparent that damage has occurred and the vaccine becomes ineffective. For some products, going over temperature, even only briefly, can reduce shelf life dramatically, incurring substantial costs when it cannot be sold. Organizations contracting to ship perishable products often specify the permissible temperature range. However, even if it is possible to show that product was exposed to conditions outside of those contracted, proving where it happened, and thus responsibility, can be much harder.","title":"Introduction"},{"location":"predictive-maintenance/#predictive-maintenance-problem-statement","text":"The success of predictive maintenance models depend on three main components: having the right data framing the problem appropriately evaluating the predictions properly From a methodology point of view the Data Scientist needs to address the following questions: What type of failure to consider and which one to predict? What kind of failure is happening? slow degradation or instantaneous failure? What could be the relation between a product characteristics and the failure? What kind of measure exist to assess the given characteristic? Which measurements correspond to good functioning and which ones correspond to failure? How often metrics are reported? What question the model should answer? What kind of output should the model give? How long in advance should the model be able to indicate that a failure will occur? What are the business impact to do not predict the failure? and predicting false negative failure? What is the expected accuracy?","title":"Predictive maintenance problem statement"},{"location":"predictive-maintenance/#reefer-problem-types","text":"There are multiple different potential issues that could happen to a refrigerator container. We are choosing to model the \"Sensor Malfunctions\" issue: Sensors in the refrigeration unit need to be calibrated and be continuously operational. An example of failure may come from the air sensor making inaccurate readings of temperatures, which leads to sploiled content. A potential reason may come from a faulty calibration, which can go unnoticed for a good time period. It may be difficult to know if there is an issue or not. The other common potential issues are: Fluid leaks, like engine oil, coolant liquid. The preassure sensors added to the circuit may help identify preassure lost over time. Faulty belts and hoses. Faulty calibration: A non-calibrated reefer can cool at a slower or faster rate than desired. Damaged Air Chute. Condenser Issues like broken or damaged coils, clamps or bolts missing, and leaks. Door Seals damaged. Blocked air passage: to keep the temperature homogenous inside the reefer. So the question we want to answer is: does the Reefer keep accurate temperature overtime between what is set versus what is measured?","title":"Reefer problem types"},{"location":"predictive-maintenance/#modeling-techniques","text":"The model uses the generated data from above scenarios: When the container's door is open for a longer time - this gives a false positive that maintainence is required. When sensors are malfunctioning, it records arbitrary readings. When the readings are normal. We have currently trained our model on 3000 datapoints from the three scenarios above. There are different modeling approach to tackle predictive maintenance: regression model classification to predict failure for a given time period classify anomalous behavior: classes are not known in advance. Normal operation is known. compute probability of failure over time","title":"Modeling techniques"},{"location":"predictive-maintenance/#code-execution","text":"The simulator continuosly generates container metrics, publishes it to Kafka and run the predictMaintainence.ipynb to predict if maintainence is sought at this point in time.","title":"Code execution"},{"location":"predictive-maintenance/#model-description","text":"We are using Machine Learning supervised learning here. There are two types of supervised learning - 1) Classification: Predict a categorical response, 2) Regression: Predict a continuous response","title":"Model description"},{"location":"predictive-maintenance/#linear-regression","text":"Pros: 1) Fast 2) No tuning required 3) Highly interpretable 4) Well-understood Cons: 1) Unlikely to produce the best predictive accuracy 2) Presumes a linear relationship between the features and response 3) If the relationship is highly non-linear as with many scenarios, linear relationship will not effectively model the relationship and its prediction would not be accurate","title":"Linear regression"},{"location":"predictive-maintenance/#naive-bayes-classification","text":"Naive Bayes is a probabilistic classifier inspired by the Bayes theorem under a simple assumption which is the attributes are conditionally independent. The classification is conducted by deriving the maximum posterior which is the maximal P(Ci|X) with the above assumption applying to Bayes theorem. This assumption greatly reduces the computational cost by only counting the class distribution. Even though the assumption is not valid in most cases since the attributes are dependent, surprisingly Naive Bayes has able to perform impressively. Naive Bayes is a very simple algorithm to implement and good results have obtained in most cases. It can be easily scalable to larger datasets since it takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers. Naive Bayes can suffer from a problem called the zero probability problem. When the conditional probability is zero for a particular attribute, it fails to give a valid prediction. This needs to be fixed explicitly using a Laplacian estimator.","title":"Naive Bayes classification"},{"location":"predictive-maintenance/#model-evaluation","text":"We are using Root Mean Squared Error (RMSE) for evaluating the model performance. Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors. Classification does better here as the scenarion is more of a classification problem.","title":"Model evaluation"},{"location":"predictive-maintenance/#references","text":"Understand Reefer container For modeling predictive maintenance we found this article from BigData Republique, on Medium, very interesting. PREDICTION OF TEMPERATURE INSIDE A REFRIGERATED CONTAINER IN THE PRESENCE OF PERISHABLE GOODS Temperature Monitoring During Transportation, Storage and Processing of Perishable Products Understanding machine learning classifiers","title":"References"}]}