{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>Temperature(celsius)</th>\n",
       "      <th>Target_Temperature(celsius)</th>\n",
       "      <th>Power</th>\n",
       "      <th>PowerConsumption</th>\n",
       "      <th>ContentType</th>\n",
       "      <th>O2</th>\n",
       "      <th>CO2</th>\n",
       "      <th>Time_Door_Open</th>\n",
       "      <th>Maintenance_Required</th>\n",
       "      <th>Defrost_Cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-16 23:41:28.424611</td>\n",
       "      <td>101</td>\n",
       "      <td>1.448400</td>\n",
       "      <td>4</td>\n",
       "      <td>17.022871</td>\n",
       "      <td>20.790347</td>\n",
       "      <td>2</td>\n",
       "      <td>21.036842</td>\n",
       "      <td>2.311549</td>\n",
       "      <td>31.458286</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-16 23:56:28.424611</td>\n",
       "      <td>101</td>\n",
       "      <td>3.429018</td>\n",
       "      <td>4</td>\n",
       "      <td>3.592812</td>\n",
       "      <td>24.383160</td>\n",
       "      <td>2</td>\n",
       "      <td>19.376279</td>\n",
       "      <td>8.208501</td>\n",
       "      <td>25.424173</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-17 00:11:28.424611</td>\n",
       "      <td>101</td>\n",
       "      <td>2.128647</td>\n",
       "      <td>4</td>\n",
       "      <td>19.358125</td>\n",
       "      <td>43.741285</td>\n",
       "      <td>2</td>\n",
       "      <td>20.905647</td>\n",
       "      <td>12.769884</td>\n",
       "      <td>32.355962</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-09-17 00:26:28.424611</td>\n",
       "      <td>101</td>\n",
       "      <td>7.606698</td>\n",
       "      <td>4</td>\n",
       "      <td>8.977030</td>\n",
       "      <td>52.718315</td>\n",
       "      <td>2</td>\n",
       "      <td>25.174083</td>\n",
       "      <td>3.584314</td>\n",
       "      <td>28.840481</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-09-17 00:41:28.424611</td>\n",
       "      <td>101</td>\n",
       "      <td>3.870544</td>\n",
       "      <td>4</td>\n",
       "      <td>6.738919</td>\n",
       "      <td>59.457234</td>\n",
       "      <td>2</td>\n",
       "      <td>15.753765</td>\n",
       "      <td>-3.815855</td>\n",
       "      <td>30.820754</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   Timestamp   ID  Temperature(celsius)  \\\n",
       "0           0  2019-09-16 23:41:28.424611  101              1.448400   \n",
       "1           1  2019-09-16 23:56:28.424611  101              3.429018   \n",
       "2           2  2019-09-17 00:11:28.424611  101              2.128647   \n",
       "3           3  2019-09-17 00:26:28.424611  101              7.606698   \n",
       "4           4  2019-09-17 00:41:28.424611  101              3.870544   \n",
       "\n",
       "   Target_Temperature(celsius)      Power  PowerConsumption  ContentType  \\\n",
       "0                            4  17.022871         20.790347            2   \n",
       "1                            4   3.592812         24.383160            2   \n",
       "2                            4  19.358125         43.741285            2   \n",
       "3                            4   8.977030         52.718315            2   \n",
       "4                            4   6.738919         59.457234            2   \n",
       "\n",
       "          O2        CO2  Time_Door_Open  Maintenance_Required  Defrost_Cycle  \n",
       "0  21.036842   2.311549       31.458286                     0              6  \n",
       "1  19.376279   8.208501       25.424173                     0              4  \n",
       "2  20.905647  12.769884       32.355962                     0              1  \n",
       "3  25.174083   3.584314       28.840481                     0              4  \n",
       "4  15.753765  -3.815855       30.820754                     0              3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset - the generated simulator data\n",
    "data = pd.read_csv('./data/metrics.csv', delimiter=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.44839974,  4.        , 17.02287069, 20.79034749,  2.        ,\n",
       "        21.03684175,  2.3115489 , 31.45828622,  6.        ],\n",
       "       [ 3.42901817,  4.        ,  3.59281214, 24.38315962,  2.        ,\n",
       "        19.37627866,  8.20850067, 25.42417332,  4.        ],\n",
       "       [ 2.1286465 ,  4.        , 19.35812534, 43.74128497,  2.        ,\n",
       "        20.90564696, 12.76988397, 32.35596162,  1.        ],\n",
       "       [ 7.60669751,  4.        ,  8.97703011, 52.71831508,  2.        ,\n",
       "        25.17408283,  3.58431369, 28.84048139,  4.        ],\n",
       "       [ 3.87054371,  4.        ,  6.73891933, 59.45723441,  2.        ,\n",
       "        15.75376503, -3.81585455, 30.82075413,  3.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataset into array for the independent variables (features)\n",
    "X = np.asarray(data[['Temperature(celsius)','Target_Temperature(celsius)','Power','PowerConsumption','ContentType','O2','CO2','Time_Door_Open','Defrost_Cycle']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataset into array for the dependent (objective) variables\n",
    "y = np.asarray(data['Maintenance_Required'])\n",
    "#y = np.asarray(data['Maintainence_Required'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.78830883,  0.        ,  1.80536954, -0.791233  ,  0.        ,\n",
       "         0.02944169, -0.56421539,  0.68968588,  1.52733065],\n",
       "       [-0.44453391,  0.        , -0.3947635 , -0.78965296,  0.        ,\n",
       "        -0.51282631,  1.39669983, -2.37935883,  0.5133352 ],\n",
       "       [-0.67023875,  0.        ,  2.18793459, -0.78113966,  0.        ,\n",
       "        -0.01340084,  2.91349804,  1.14625771, -1.00765798],\n",
       "       [ 0.28058375,  0.        ,  0.48728745, -0.77719174,  0.        ,\n",
       "         1.38048549, -0.14098252, -0.64177082,  0.5133352 ],\n",
       "       [-0.36789855,  0.        ,  0.12063666, -0.77422811,  0.        ,\n",
       "        -1.69578241, -2.60176278,  0.36542703,  0.00633747]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize/standardize (mean = 0 and standard deviation = 1) \n",
    "# your features before applying machine learning techniques.\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (1600, 9) (1600,)\n",
      "Test set: (400, 9) (400,)\n"
     ]
    }
   ],
   "source": [
    "## split the dataset into train and test to estiamte model accuracy \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## As we are trying to acheive a binary classification, we use Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15830492,  0.        ,  0.03690305,  0.77966287,  0.        ,\n",
       "        -0.01955488,  0.44335135,  0.07408011,  0.05635899]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predict using the trained LR model\n",
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47766703, 0.52233297],\n",
       "       [0.78247702, 0.21752298],\n",
       "       [0.44081017, 0.55918983],\n",
       "       [0.76834367, 0.23165633],\n",
       "       [0.81540078, 0.18459922],\n",
       "       [0.45814685, 0.54185315],\n",
       "       [0.39827836, 0.60172164],\n",
       "       [0.27863134, 0.72136866],\n",
       "       [0.89814321, 0.10185679],\n",
       "       [0.61161381, 0.38838619],\n",
       "       [0.74505992, 0.25494008],\n",
       "       [0.62753913, 0.37246087],\n",
       "       [0.88749762, 0.11250238],\n",
       "       [0.82621609, 0.17378391],\n",
       "       [0.72557427, 0.27442573],\n",
       "       [0.82591643, 0.17408357],\n",
       "       [0.65140111, 0.34859889],\n",
       "       [0.64633487, 0.35366513],\n",
       "       [0.71378742, 0.28621258],\n",
       "       [0.73960416, 0.26039584],\n",
       "       [0.59583515, 0.40416485],\n",
       "       [0.2869435 , 0.7130565 ],\n",
       "       [0.80938731, 0.19061269],\n",
       "       [0.22391735, 0.77608265],\n",
       "       [0.75772979, 0.24227021],\n",
       "       [0.62244757, 0.37755243],\n",
       "       [0.67710582, 0.32289418],\n",
       "       [0.67701687, 0.32298313],\n",
       "       [0.76948842, 0.23051158],\n",
       "       [0.11413944, 0.88586056],\n",
       "       [0.84477866, 0.15522134],\n",
       "       [0.69966896, 0.30033104],\n",
       "       [0.21538423, 0.78461577],\n",
       "       [0.7842867 , 0.2157133 ],\n",
       "       [0.51640474, 0.48359526],\n",
       "       [0.82681622, 0.17318378],\n",
       "       [0.2038638 , 0.7961362 ],\n",
       "       [0.68227105, 0.31772895],\n",
       "       [0.76975044, 0.23024956],\n",
       "       [0.68965804, 0.31034196],\n",
       "       [0.80633885, 0.19366115],\n",
       "       [0.64289666, 0.35710334],\n",
       "       [0.70258811, 0.29741189],\n",
       "       [0.30921693, 0.69078307],\n",
       "       [0.57229865, 0.42770135],\n",
       "       [0.68320614, 0.31679386],\n",
       "       [0.3714455 , 0.6285545 ],\n",
       "       [0.66659415, 0.33340585],\n",
       "       [0.87031699, 0.12968301],\n",
       "       [0.79803525, 0.20196475],\n",
       "       [0.31115876, 0.68884124],\n",
       "       [0.57324443, 0.42675557],\n",
       "       [0.86515605, 0.13484395],\n",
       "       [0.48723116, 0.51276884],\n",
       "       [0.61870372, 0.38129628],\n",
       "       [0.77719903, 0.22280097],\n",
       "       [0.75689938, 0.24310062],\n",
       "       [0.82084393, 0.17915607],\n",
       "       [0.28460307, 0.71539693],\n",
       "       [0.82014652, 0.17985348],\n",
       "       [0.55717715, 0.44282285],\n",
       "       [0.64760122, 0.35239878],\n",
       "       [0.4819676 , 0.5180324 ],\n",
       "       [0.80290728, 0.19709272],\n",
       "       [0.68466797, 0.31533203],\n",
       "       [0.86241022, 0.13758978],\n",
       "       [0.51098919, 0.48901081],\n",
       "       [0.61335994, 0.38664006],\n",
       "       [0.78173442, 0.21826558],\n",
       "       [0.2340482 , 0.7659518 ],\n",
       "       [0.23863941, 0.76136059],\n",
       "       [0.20663848, 0.79336152],\n",
       "       [0.81749525, 0.18250475],\n",
       "       [0.80617304, 0.19382696],\n",
       "       [0.61596793, 0.38403207],\n",
       "       [0.3460404 , 0.6539596 ],\n",
       "       [0.47581829, 0.52418171],\n",
       "       [0.63371126, 0.36628874],\n",
       "       [0.81006452, 0.18993548],\n",
       "       [0.65905043, 0.34094957],\n",
       "       [0.8143966 , 0.1856034 ],\n",
       "       [0.77524724, 0.22475276],\n",
       "       [0.33832253, 0.66167747],\n",
       "       [0.77462376, 0.22537624],\n",
       "       [0.86194198, 0.13805802],\n",
       "       [0.63486292, 0.36513708],\n",
       "       [0.63353985, 0.36646015],\n",
       "       [0.62366351, 0.37633649],\n",
       "       [0.47274449, 0.52725551],\n",
       "       [0.74183708, 0.25816292],\n",
       "       [0.35336813, 0.64663187],\n",
       "       [0.7534797 , 0.2465203 ],\n",
       "       [0.3790592 , 0.6209408 ],\n",
       "       [0.59972938, 0.40027062],\n",
       "       [0.78359929, 0.21640071],\n",
       "       [0.69720987, 0.30279013],\n",
       "       [0.70119687, 0.29880313],\n",
       "       [0.71566209, 0.28433791],\n",
       "       [0.41738297, 0.58261703],\n",
       "       [0.71387077, 0.28612923],\n",
       "       [0.58697391, 0.41302609],\n",
       "       [0.69321496, 0.30678504],\n",
       "       [0.61435725, 0.38564275],\n",
       "       [0.75620044, 0.24379956],\n",
       "       [0.84474837, 0.15525163],\n",
       "       [0.84109963, 0.15890037],\n",
       "       [0.8110229 , 0.1889771 ],\n",
       "       [0.75155042, 0.24844958],\n",
       "       [0.65714003, 0.34285997],\n",
       "       [0.60216253, 0.39783747],\n",
       "       [0.79429994, 0.20570006],\n",
       "       [0.78877269, 0.21122731],\n",
       "       [0.3819816 , 0.6180184 ],\n",
       "       [0.75400159, 0.24599841],\n",
       "       [0.36272324, 0.63727676],\n",
       "       [0.35560221, 0.64439779],\n",
       "       [0.55585535, 0.44414465],\n",
       "       [0.63769601, 0.36230399],\n",
       "       [0.6131391 , 0.3868609 ],\n",
       "       [0.72032397, 0.27967603],\n",
       "       [0.75708672, 0.24291328],\n",
       "       [0.27018106, 0.72981894],\n",
       "       [0.70640821, 0.29359179],\n",
       "       [0.80720337, 0.19279663],\n",
       "       [0.68092543, 0.31907457],\n",
       "       [0.27771565, 0.72228435],\n",
       "       [0.74743018, 0.25256982],\n",
       "       [0.39297771, 0.60702229],\n",
       "       [0.47573694, 0.52426306],\n",
       "       [0.69144386, 0.30855614],\n",
       "       [0.39005809, 0.60994191],\n",
       "       [0.77099016, 0.22900984],\n",
       "       [0.89658495, 0.10341505],\n",
       "       [0.64406248, 0.35593752],\n",
       "       [0.54093795, 0.45906205],\n",
       "       [0.30148497, 0.69851503],\n",
       "       [0.78208415, 0.21791585],\n",
       "       [0.81073827, 0.18926173],\n",
       "       [0.52048843, 0.47951157],\n",
       "       [0.67698061, 0.32301939],\n",
       "       [0.37810082, 0.62189918],\n",
       "       [0.58471353, 0.41528647],\n",
       "       [0.66944249, 0.33055751],\n",
       "       [0.74590841, 0.25409159],\n",
       "       [0.6510699 , 0.3489301 ],\n",
       "       [0.72761227, 0.27238773],\n",
       "       [0.79598907, 0.20401093],\n",
       "       [0.59895204, 0.40104796],\n",
       "       [0.84767828, 0.15232172],\n",
       "       [0.84482527, 0.15517473],\n",
       "       [0.64399135, 0.35600865],\n",
       "       [0.67436447, 0.32563553],\n",
       "       [0.86159976, 0.13840024],\n",
       "       [0.47020006, 0.52979994],\n",
       "       [0.79641562, 0.20358438],\n",
       "       [0.71460882, 0.28539118],\n",
       "       [0.72839369, 0.27160631],\n",
       "       [0.5162599 , 0.4837401 ],\n",
       "       [0.63788175, 0.36211825],\n",
       "       [0.78648334, 0.21351666],\n",
       "       [0.7764108 , 0.2235892 ],\n",
       "       [0.81447702, 0.18552298],\n",
       "       [0.27847308, 0.72152692],\n",
       "       [0.878257  , 0.121743  ],\n",
       "       [0.48877981, 0.51122019],\n",
       "       [0.28569144, 0.71430856],\n",
       "       [0.77351226, 0.22648774],\n",
       "       [0.80020426, 0.19979574],\n",
       "       [0.47426869, 0.52573131],\n",
       "       [0.73251605, 0.26748395],\n",
       "       [0.66121017, 0.33878983],\n",
       "       [0.49472916, 0.50527084],\n",
       "       [0.75348286, 0.24651714],\n",
       "       [0.71887104, 0.28112896],\n",
       "       [0.75530866, 0.24469134],\n",
       "       [0.56802023, 0.43197977],\n",
       "       [0.7856112 , 0.2143888 ],\n",
       "       [0.41402777, 0.58597223],\n",
       "       [0.65298673, 0.34701327],\n",
       "       [0.41836445, 0.58163555],\n",
       "       [0.48776888, 0.51223112],\n",
       "       [0.76287103, 0.23712897],\n",
       "       [0.65485015, 0.34514985],\n",
       "       [0.24993422, 0.75006578],\n",
       "       [0.6100568 , 0.3899432 ],\n",
       "       [0.73913157, 0.26086843],\n",
       "       [0.77304573, 0.22695427],\n",
       "       [0.84824667, 0.15175333],\n",
       "       [0.8347052 , 0.1652948 ],\n",
       "       [0.8641969 , 0.1358031 ],\n",
       "       [0.68417307, 0.31582693],\n",
       "       [0.41901082, 0.58098918],\n",
       "       [0.75314356, 0.24685644],\n",
       "       [0.40857841, 0.59142159],\n",
       "       [0.78376064, 0.21623936],\n",
       "       [0.76473417, 0.23526583],\n",
       "       [0.60956805, 0.39043195],\n",
       "       [0.74448839, 0.25551161],\n",
       "       [0.40276103, 0.59723897],\n",
       "       [0.49676229, 0.50323771],\n",
       "       [0.60276432, 0.39723568],\n",
       "       [0.7605022 , 0.2394978 ],\n",
       "       [0.66320847, 0.33679153],\n",
       "       [0.25578272, 0.74421728],\n",
       "       [0.44772544, 0.55227456],\n",
       "       [0.46840862, 0.53159138],\n",
       "       [0.64121944, 0.35878056],\n",
       "       [0.50249293, 0.49750707],\n",
       "       [0.65687274, 0.34312726],\n",
       "       [0.83989121, 0.16010879],\n",
       "       [0.41875926, 0.58124074],\n",
       "       [0.44413779, 0.55586221],\n",
       "       [0.73472679, 0.26527321],\n",
       "       [0.83553526, 0.16446474],\n",
       "       [0.62692196, 0.37307804],\n",
       "       [0.7561489 , 0.2438511 ],\n",
       "       [0.30252994, 0.69747006],\n",
       "       [0.7761837 , 0.2238163 ],\n",
       "       [0.7073524 , 0.2926476 ],\n",
       "       [0.68684854, 0.31315146],\n",
       "       [0.21818784, 0.78181216],\n",
       "       [0.63930914, 0.36069086],\n",
       "       [0.67652296, 0.32347704],\n",
       "       [0.49530683, 0.50469317],\n",
       "       [0.80120333, 0.19879667],\n",
       "       [0.58085724, 0.41914276],\n",
       "       [0.69534402, 0.30465598],\n",
       "       [0.6859921 , 0.3140079 ],\n",
       "       [0.54531889, 0.45468111],\n",
       "       [0.683411  , 0.316589  ],\n",
       "       [0.75104702, 0.24895298],\n",
       "       [0.66536711, 0.33463289],\n",
       "       [0.73825043, 0.26174957],\n",
       "       [0.76357379, 0.23642621],\n",
       "       [0.64036518, 0.35963482],\n",
       "       [0.31315457, 0.68684543],\n",
       "       [0.81929509, 0.18070491],\n",
       "       [0.72113318, 0.27886682],\n",
       "       [0.35419237, 0.64580763],\n",
       "       [0.78657412, 0.21342588],\n",
       "       [0.83715887, 0.16284113],\n",
       "       [0.80491392, 0.19508608],\n",
       "       [0.74083066, 0.25916934],\n",
       "       [0.45435314, 0.54564686],\n",
       "       [0.84674622, 0.15325378],\n",
       "       [0.80923981, 0.19076019],\n",
       "       [0.29258711, 0.70741289],\n",
       "       [0.27976167, 0.72023833],\n",
       "       [0.3551428 , 0.6448572 ],\n",
       "       [0.78418896, 0.21581104],\n",
       "       [0.56813742, 0.43186258],\n",
       "       [0.79529256, 0.20470744],\n",
       "       [0.33761555, 0.66238445],\n",
       "       [0.68343796, 0.31656204],\n",
       "       [0.52465645, 0.47534355],\n",
       "       [0.75672463, 0.24327537],\n",
       "       [0.79803326, 0.20196674],\n",
       "       [0.75041318, 0.24958682],\n",
       "       [0.80400748, 0.19599252],\n",
       "       [0.62798038, 0.37201962],\n",
       "       [0.56612578, 0.43387422],\n",
       "       [0.67102499, 0.32897501],\n",
       "       [0.27083659, 0.72916341],\n",
       "       [0.30900022, 0.69099978],\n",
       "       [0.83019832, 0.16980168],\n",
       "       [0.49944489, 0.50055511],\n",
       "       [0.50063167, 0.49936833],\n",
       "       [0.60588477, 0.39411523],\n",
       "       [0.33915647, 0.66084353],\n",
       "       [0.45445271, 0.54554729],\n",
       "       [0.20529221, 0.79470779],\n",
       "       [0.71291228, 0.28708772],\n",
       "       [0.91336445, 0.08663555],\n",
       "       [0.47594749, 0.52405251],\n",
       "       [0.75451637, 0.24548363],\n",
       "       [0.78732894, 0.21267106],\n",
       "       [0.59066303, 0.40933697],\n",
       "       [0.87435716, 0.12564284],\n",
       "       [0.53249357, 0.46750643],\n",
       "       [0.79151527, 0.20848473],\n",
       "       [0.70846073, 0.29153927],\n",
       "       [0.51586039, 0.48413961],\n",
       "       [0.80622848, 0.19377152],\n",
       "       [0.75972608, 0.24027392],\n",
       "       [0.69326651, 0.30673349],\n",
       "       [0.60434074, 0.39565926],\n",
       "       [0.40675996, 0.59324004],\n",
       "       [0.53790191, 0.46209809],\n",
       "       [0.29531513, 0.70468487],\n",
       "       [0.32131599, 0.67868401],\n",
       "       [0.51326655, 0.48673345],\n",
       "       [0.7109478 , 0.2890522 ],\n",
       "       [0.58865541, 0.41134459],\n",
       "       [0.81162216, 0.18837784],\n",
       "       [0.73013233, 0.26986767],\n",
       "       [0.46548441, 0.53451559],\n",
       "       [0.48692564, 0.51307436],\n",
       "       [0.65516177, 0.34483823],\n",
       "       [0.75691657, 0.24308343],\n",
       "       [0.51449636, 0.48550364],\n",
       "       [0.35674345, 0.64325655],\n",
       "       [0.67862995, 0.32137005],\n",
       "       [0.79358425, 0.20641575],\n",
       "       [0.56303122, 0.43696878],\n",
       "       [0.49109302, 0.50890698],\n",
       "       [0.65032556, 0.34967444],\n",
       "       [0.60655013, 0.39344987],\n",
       "       [0.82327117, 0.17672883],\n",
       "       [0.82813844, 0.17186156],\n",
       "       [0.58822387, 0.41177613],\n",
       "       [0.20839733, 0.79160267],\n",
       "       [0.80955928, 0.19044072],\n",
       "       [0.19678052, 0.80321948],\n",
       "       [0.79710296, 0.20289704],\n",
       "       [0.68330855, 0.31669145],\n",
       "       [0.36716687, 0.63283313],\n",
       "       [0.75906514, 0.24093486],\n",
       "       [0.1689452 , 0.8310548 ],\n",
       "       [0.74251444, 0.25748556],\n",
       "       [0.29328092, 0.70671908],\n",
       "       [0.62971885, 0.37028115],\n",
       "       [0.61285867, 0.38714133],\n",
       "       [0.45912715, 0.54087285],\n",
       "       [0.2553783 , 0.7446217 ],\n",
       "       [0.78248111, 0.21751889],\n",
       "       [0.73252975, 0.26747025],\n",
       "       [0.54052983, 0.45947017],\n",
       "       [0.47554789, 0.52445211],\n",
       "       [0.68600578, 0.31399422],\n",
       "       [0.68991145, 0.31008855],\n",
       "       [0.73976704, 0.26023296],\n",
       "       [0.26078308, 0.73921692],\n",
       "       [0.23207244, 0.76792756],\n",
       "       [0.82801344, 0.17198656],\n",
       "       [0.75226199, 0.24773801],\n",
       "       [0.10771728, 0.89228272],\n",
       "       [0.72752582, 0.27247418],\n",
       "       [0.82236242, 0.17763758],\n",
       "       [0.53669008, 0.46330992],\n",
       "       [0.68135736, 0.31864264],\n",
       "       [0.73242917, 0.26757083],\n",
       "       [0.59088921, 0.40911079],\n",
       "       [0.69677413, 0.30322587],\n",
       "       [0.72783201, 0.27216799],\n",
       "       [0.57169001, 0.42830999],\n",
       "       [0.80692947, 0.19307053],\n",
       "       [0.78026271, 0.21973729],\n",
       "       [0.63469141, 0.36530859],\n",
       "       [0.75003062, 0.24996938],\n",
       "       [0.74064225, 0.25935775],\n",
       "       [0.40516756, 0.59483244],\n",
       "       [0.70661976, 0.29338024],\n",
       "       [0.76452761, 0.23547239],\n",
       "       [0.70193815, 0.29806185],\n",
       "       [0.17776463, 0.82223537],\n",
       "       [0.36453128, 0.63546872],\n",
       "       [0.34955001, 0.65044999],\n",
       "       [0.4661979 , 0.5338021 ],\n",
       "       [0.86565843, 0.13434157],\n",
       "       [0.46302786, 0.53697214],\n",
       "       [0.53092093, 0.46907907],\n",
       "       [0.81022224, 0.18977776],\n",
       "       [0.74563914, 0.25436086],\n",
       "       [0.48574292, 0.51425708],\n",
       "       [0.73635534, 0.26364466],\n",
       "       [0.86712411, 0.13287589],\n",
       "       [0.78370953, 0.21629047],\n",
       "       [0.80331848, 0.19668152],\n",
       "       [0.71224572, 0.28775428],\n",
       "       [0.78928936, 0.21071064],\n",
       "       [0.32085011, 0.67914989],\n",
       "       [0.70353156, 0.29646844],\n",
       "       [0.76936594, 0.23063406],\n",
       "       [0.47811339, 0.52188661],\n",
       "       [0.61587225, 0.38412775],\n",
       "       [0.82405574, 0.17594426],\n",
       "       [0.3948769 , 0.6051231 ],\n",
       "       [0.62738435, 0.37261565],\n",
       "       [0.82508114, 0.17491886],\n",
       "       [0.43824242, 0.56175758],\n",
       "       [0.74392269, 0.25607731],\n",
       "       [0.68213286, 0.31786714],\n",
       "       [0.7699208 , 0.2300792 ],\n",
       "       [0.66659182, 0.33340818],\n",
       "       [0.53133376, 0.46866624],\n",
       "       [0.38426834, 0.61573166],\n",
       "       [0.65951465, 0.34048535],\n",
       "       [0.78095192, 0.21904808],\n",
       "       [0.70871476, 0.29128524],\n",
       "       [0.65590519, 0.34409481],\n",
       "       [0.84482065, 0.15517935],\n",
       "       [0.76405233, 0.23594767],\n",
       "       [0.63756276, 0.36243724],\n",
       "       [0.74342986, 0.25657014],\n",
       "       [0.7430192 , 0.2569808 ],\n",
       "       [0.83970219, 0.16029781],\n",
       "       [0.70549439, 0.29450561],\n",
       "       [0.78245991, 0.21754009],\n",
       "       [0.6548042 , 0.3451958 ],\n",
       "       [0.84963462, 0.15036538]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38461538461538464"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    print(confusion_matrix(y_test, yhat, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['MaintFlag=1','MaintFlag=0'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       286\n",
      "           1       0.59      0.53      0.56       114\n",
      "\n",
      "    accuracy                           0.76       400\n",
      "   macro avg       0.70      0.69      0.70       400\n",
      "weighted avg       0.75      0.76      0.76       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5206027539762208"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, yhat_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#serializing our model to a file called model_logistic_regression.pkl\n",
    "pickle.dump(LR, open(\"model_logistic_regression.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
